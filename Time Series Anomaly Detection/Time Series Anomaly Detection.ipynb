{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7aac99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd349d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         value\n",
      "timestamp                     \n",
      "2014-04-01 00:00:00  18.324919\n",
      "2014-04-01 00:05:00  21.970327\n",
      "2014-04-01 00:10:00  18.624806\n",
      "2014-04-01 00:15:00  21.953684\n",
      "2014-04-01 00:20:00  21.909120\n",
      "                         value\n",
      "timestamp                     \n",
      "2014-04-01 00:00:00  19.761252\n",
      "2014-04-01 00:05:00  20.500833\n",
      "2014-04-01 00:10:00  19.961641\n",
      "2014-04-01 00:15:00  21.490266\n",
      "2014-04-01 00:20:00  20.187739\n",
      "Number of training samples: 4032\n",
      "Training input shape:  (3745, 288, 1)\n"
     ]
    }
   ],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(df_small_noise.head())\n",
    "\n",
    "print(df_daily_jumpsup.head())\n",
    "\n",
    "\n",
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))\n",
    "\n",
    "\n",
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f96902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 144, 32)           256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 144, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 72, 16)            3600      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 144, 16)           1808      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 288, 32)           3616      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 288, 1)            225       \n",
      "=================================================================\n",
      "Total params: 9,505\n",
      "Trainable params: 9,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f5fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 11s 35ms/step - loss: 0.4979 - val_loss: 0.0985\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0796 - val_loss: 0.0383\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0560 - val_loss: 0.0344\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0476 - val_loss: 0.0300\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0413 - val_loss: 0.0275\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0364 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0241\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0296 - val_loss: 0.0240\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0235\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0248\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0245\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0248\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 0.0273\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.0285\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15a13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_train_pred.npy\", x_train_pred)\n",
    "np.save(\"train_mae_loss.npy\", train_mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b45a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error threshold:  0.12863194435425318\n"
     ]
    }
   ],
   "source": [
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bcc7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_value = (df_daily_jumpsup - training_mean) / training_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e838f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input shape:  (3745, 288, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = create_sequences(df_test_value.values)\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "test_mae_loss = test_mae_loss.reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb47aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_test_pred.npy\", x_test_pred)\n",
    "np.save(\"test_mae_loss.npy\", test_mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb3653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomaly samples:  392\n",
      "Indices of anomaly samples:  (array([2702, 2703, 2704, 2705, 2706, 2708, 2709, 2710, 2711, 2712, 2713,\n",
      "       2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724,\n",
      "       2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735,\n",
      "       2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746,\n",
      "       2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757,\n",
      "       2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768,\n",
      "       2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779,\n",
      "       2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790,\n",
      "       2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801,\n",
      "       2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812,\n",
      "       2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823,\n",
      "       2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834,\n",
      "       2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845,\n",
      "       2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856,\n",
      "       2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867,\n",
      "       2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878,\n",
      "       2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889,\n",
      "       2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900,\n",
      "       2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911,\n",
      "       2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922,\n",
      "       2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933,\n",
      "       2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944,\n",
      "       2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955,\n",
      "       2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966,\n",
      "       2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977,\n",
      "       2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988,\n",
      "       2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999,\n",
      "       3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010,\n",
      "       3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021,\n",
      "       3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032,\n",
      "       3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043,\n",
      "       3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054,\n",
      "       3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065,\n",
      "       3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076,\n",
      "       3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087,\n",
      "       3089, 3090, 3091, 3092, 3093, 3094, 3095], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9d62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
    "        anomalous_data_indices.append(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fc92e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anomalous_data_indices.npy\",anomalous_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb076c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
